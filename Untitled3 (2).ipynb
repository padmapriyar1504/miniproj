{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253cb32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 50, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " vgg16 (Functional)          (None, 1, 1, 512)            1471468   ['input_1[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " resnet50 (Functional)       (None, 2, 2, 2048)           2358771   ['input_1[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 512)                  0         ['vgg16[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 8192)                 0         ['resnet50[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 4096)                 2101248   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4096)                 3355852   ['flatten_1[0][0]']           \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2048)                 8390656   ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2048)                 8390656   ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 4096)                 0         ['dense_1[0][0]',             \n",
      "                                                                     'dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 8192)                 3356262   ['concatenate[0][0]']         \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 4096)                 3355852   ['dense_4[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 50)                   204850    ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158069490 (602.99 MB)\n",
      "Trainable params: 119767090 (456.88 MB)\n",
      "Non-trainable params: 38302400 (146.11 MB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "404/404 [==============================] - 1215s 3s/step - loss: 1.8106 - accuracy: 0.4794 - val_loss: 0.4047 - val_accuracy: 0.8543\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 1118s 3s/step - loss: 0.3120 - accuracy: 0.8916 - val_loss: 0.0873 - val_accuracy: 0.9737\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 1117s 3s/step - loss: 0.2103 - accuracy: 0.9324 - val_loss: 0.2576 - val_accuracy: 0.9496\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 1700s 4s/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 1.8709e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 1299s 3s/step - loss: 9.3159e-05 - accuracy: 1.0000 - val_loss: 5.0325e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 1222s 3s/step - loss: 3.4352e-05 - accuracy: 1.0000 - val_loss: 2.3449e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 1480s 4s/step - loss: 1.7327e-05 - accuracy: 1.0000 - val_loss: 1.2495e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 1229s 3s/step - loss: 9.9600e-06 - accuracy: 1.0000 - val_loss: 7.5084e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 971s 2s/step - loss: 6.0649e-06 - accuracy: 1.0000 - val_loss: 4.7852e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 882s 2s/step - loss: 3.8947e-06 - accuracy: 1.0000 - val_loss: 3.1638e-06 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, ResNet50\n",
    "\n",
    "def crop_image(img, padding=10):\n",
    " \n",
    "    try:\n",
    "        # Find non-zero foreground pixels\n",
    "        non_zero_pixels = cv2.findNonZero(img)\n",
    "\n",
    "        # Check if there are non-zero pixels\n",
    "        if len(non_zero_pixels) == 0:\n",
    "            return img.astype(np.uint8)  # Return original image if empty\n",
    "\n",
    "        # Get bounding rectangle coordinates\n",
    "        x, y, w, h = cv2.boundingRect(non_zero_pixels)\n",
    "\n",
    "        # Apply padding to the bounding box\n",
    "        x = max(0, x - padding)\n",
    "        y = max(0, y - padding)\n",
    "        w = min(img.shape[1], x + w + 2 * padding)\n",
    "        h = min(img.shape[0], y + h + 2 * padding)\n",
    "\n",
    "        # Crop the image\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "        return crop.astype(np.uint8)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during cropping:\", e)\n",
    "        return img.astype(np.uint8)  # Return original image on error\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, label_folder in enumerate(os.listdir(folder)):\n",
    "        label_folder_path = os.path.join(folder, label_folder)\n",
    "        for filename in os.listdir(label_folder_path):\n",
    "            img_path = os.path.join(label_folder_path, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "            img = crop_image(img)  # Apply preprocessing step\n",
    "            img = cv2.resize(img, (50, 50))  # Resize image\n",
    "            img_array = img / 255.0  # Normalize pixel values\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess images\n",
    "X_train, y_train = load_images_from_folder(r'D:\\newkannada')\n",
    "X_test, y_test = load_images_from_folder(r'D:\\newkannada')\n",
    "\n",
    "# Repeat single channel three times to convert grayscale to RGB\n",
    "X_train_rgb = np.repeat(X_train[..., np.newaxis], 3, axis=-1)\n",
    "X_test_rgb = np.repeat(X_test[..., np.newaxis], 3, axis=-1)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train_rgb, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train_encoded = to_categorical(y_train_split)\n",
    "y_test_encoded = to_categorical(y_test_split)\n",
    "max_label = np.max(y_train_split)\n",
    "num_classes = max_label + 1\n",
    "\n",
    "# Define input layer for RGB images\n",
    "input_layer = Input(shape=(50, 50, 3))  # Input for RGB images\n",
    "\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(50, 50, 3))\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(50, 50, 3))\n",
    "for layer in resnet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass input through VGG16 model\n",
    "vgg_out = vgg_base(input_layer)\n",
    "vgg_out = Flatten()(vgg_out)\n",
    "vgg_out = Dense(4096, activation='relu')(vgg_out)\n",
    "vgg_out = Dense(2048, activation='relu')(vgg_out)\n",
    "\n",
    "# Pass input through ResNet50 model\n",
    "resnet_out = resnet_base(input_layer)\n",
    "resnet_out = Flatten()(resnet_out)\n",
    "resnet_out = Dense(4096, activation='relu')(resnet_out)\n",
    "resnet_out = Dense(2048, activation='relu')(resnet_out)\n",
    "\n",
    "# Concatenate outputs from VGG16 and ResNet50\n",
    "merged_out = Concatenate()([vgg_out, resnet_out])\n",
    "merged_out = Dense(8192, activation='relu')(merged_out)  # Increased neuron units\n",
    "merged_out = Dense(4096, activation='relu')(merged_out)  # Increased neuron units\n",
    "output_layer = Dense(num_classes, activation='softmax')(merged_out)  # Adjusted output units for 164 classes\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_split, y_train_encoded, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c87c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 103s 799ms/step\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Confusion Matrix:\n",
      "[[72  0  0 ...  0  0  0]\n",
      " [ 0 66  0 ...  0  0  0]\n",
      " [ 0  0 78 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 58  0  0]\n",
      " [ 0  0  0 ...  0 86  0]\n",
      " [ 0  0  0 ...  0  0 93]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict classes for test data\n",
    "y_pred = np.argmax(model.predict(X_test_split), axis=1)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = np.mean(y_pred == y_test_split)\n",
    "\n",
    "# Compute precision\n",
    "precision = np.sum(y_pred == y_test_split) / len(y_pred)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_split, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3872529b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  0  0 ...  0  0  0]\n",
      " [ 0 66  0 ...  0  0  0]\n",
      " [ 0  0 78 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 58  0  0]\n",
      " [ 0  0  0 ...  0 86  0]\n",
      " [ 0  0  0 ...  0  0 93]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e7a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "Predicted Label: Sample290\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load your custom image\n",
    "custom_image_path = \"Screenshot 2024-05-10 184752.png\"\n",
    "custom_img = cv2.imread(custom_image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "custom_img = cv2.resize(custom_img, (50, 50))  # Resize image\n",
    "custom_img_rgb = cv2.cvtColor(custom_img, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
    "\n",
    "# Normalize pixel values\n",
    "custom_img_rgb = custom_img_rgb / 255.0  \n",
    "\n",
    "# Reshape for model input\n",
    "custom_img_reshaped = np.expand_dims(custom_img_rgb, axis=0)\n",
    "\n",
    "# Predict label for custom image\n",
    "predicted_label_idx = np.argmax(model.predict(custom_img_reshaped), axis=1)[0]\n",
    "predicted_label_folder = os.listdir(r'D:\\newkannada')[predicted_label_idx]\n",
    "\n",
    "print(\"Predicted Label:\", predicted_label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0af2833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_path = \"kannada_model_checkpoint.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, save_weights_only=False, verbose=1)\n",
    "model.save(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8284315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model using the native Keras format\n",
    "model.save(\"my_kannada_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a5e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"kannada_model_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bddfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc440c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
